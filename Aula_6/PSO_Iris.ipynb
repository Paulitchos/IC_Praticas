{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:12:04,341 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=0.031\n",
      "2022-11-29 16:12:17,066 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.031015435826767596, best pos: [ 5.39429763e-01 -6.95472801e-02  2.90325055e-01 -1.27308812e+00\n",
      " -2.87007446e+00  6.39469264e-01  1.14739205e+00 -5.88081559e-01\n",
      " -1.04234793e+00  3.65987901e+00  4.68306819e-01  1.46464893e+00\n",
      "  4.80501582e-01 -7.20829760e-01  2.56206960e+00 -1.28790101e+00\n",
      "  4.47859826e-01  2.53106748e+00  6.35794523e-01 -3.56839969e+00\n",
      " -1.72341309e+00 -5.86088349e-01  4.08514562e-01  2.22244037e-01\n",
      "  9.95078509e-01  5.22154996e-01 -1.21593974e+00 -4.65036014e-01\n",
      " -6.37511253e-01  2.17560709e-02  2.83954113e+00 -6.88249786e-01\n",
      "  8.47390600e-01  1.81843394e+00  2.42330538e-01  1.92091171e-01\n",
      "  1.15357378e+00  8.61738437e-01  5.24035138e-01 -2.87607111e+00\n",
      "  1.09770387e+00  1.42099721e+00  7.82326922e-01  1.34451319e+00\n",
      "  7.86711562e-01  1.10008430e+00  1.48779019e+00  4.25087587e-01\n",
      "  1.78346691e+00  7.04785299e-01  1.52139157e+00  1.39133757e+00\n",
      " -2.75218941e+00 -4.05460428e-01 -1.39632657e-01  1.81048656e-01\n",
      "  3.45558042e-01  1.01895209e+00 -1.28846907e+00  7.81071568e-01\n",
      "  1.61304437e+00  1.43872396e+01  6.20473819e-01  3.43603898e-01\n",
      "  7.88211536e-01 -1.76938063e-01 -1.10748680e+00 -1.23421477e+00\n",
      "  6.16014056e-01 -1.88784249e+00  1.26711421e+00  2.67970159e+00\n",
      " -3.82469094e-01 -4.99674878e-01 -8.77792050e-01  3.96767882e-01\n",
      "  1.72458386e+00 -2.26336596e-01 -4.26300223e-01  1.07846974e+00\n",
      "  6.80034513e-01 -3.01631062e+01 -1.96419877e-01  1.71623230e+00\n",
      " -3.49931665e-01  4.36482371e-01  2.52853425e-01  2.65274472e+00\n",
      "  4.15485570e+00 -1.85409648e-01  5.31261674e-01  3.45726660e-01\n",
      "  1.67048414e+00  1.64305235e+00  1.32953599e-01  7.87260295e-01\n",
      "  7.26469335e-01  2.26835142e+00  1.02011321e+00  7.15231459e-01\n",
      "  1.20059437e+00 -6.01635256e-01 -7.41336142e-01  6.34490463e-01\n",
      " -1.20582404e+00  1.90683363e+00  1.21251865e+00  8.42441105e-01\n",
      " -2.17008829e+00 -1.21836923e+01  2.33819007e+00 -5.15444960e-01\n",
      " -1.56177091e-01  1.44583891e+00  2.83276206e-01 -2.90600451e-01\n",
      " -5.83009515e-01 -1.56634320e+00  9.05509769e-01  1.30541802e+00\n",
      " -1.34262215e-01  4.91221350e-01  4.41128204e-02 -8.52565363e-01\n",
      " -1.19739492e+00  9.85781525e-01  1.92343021e+00  8.98277677e-02\n",
      "  1.98909645e+00  3.13467690e-01  1.67924409e-01  6.79502124e-01\n",
      "  9.98050319e-01  2.64128280e-01 -2.09586550e+00  2.50219888e+00\n",
      "  9.96888478e-01 -3.81454488e+00  4.76897532e-01  1.20020632e+00\n",
      "  1.58452563e+00 -2.21880914e-02  2.96427961e-01  1.84648048e-01\n",
      " -8.22240034e-01  1.21245652e+00  1.50045076e+00  2.26215107e+00\n",
      " -1.39862892e-01  4.47744032e-03  1.15770315e+00  6.13283532e-02\n",
      "  6.55851602e-01  6.67754244e-01  9.77164393e-01  1.21456035e+01\n",
      " -1.45155985e+00 -1.51078010e+00  7.47352677e-01  1.06180948e+00\n",
      "  2.80667276e-01 -6.11150217e-01 -1.48817847e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "# Load the iris dataset\n",
    "data = load_iris()\n",
    "\n",
    "#Store the features as X and the label as y\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "def forward_prop(params):\n",
    "\n",
    "    #Neural network architecture\n",
    "    n_inputs = 4\n",
    "    n_hidden = 20\n",
    "    n_classes = 3\n",
    "\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = params[0:80].reshape((n_inputs,n_hidden))\n",
    "    b1 = params[80:100].reshape((n_hidden,))\n",
    "    W2 = params[100:160].reshape((n_hidden,n_classes))\n",
    "    b2 = params[160:163].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X.dot(W1) + b1 # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1) # Activation in Layer 1\n",
    "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    logits = z2 # Logits for Layer 2\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "    N = 150 # Number of samples\n",
    "    corect_logprobs = -np.log(probs[range(N), y])\n",
    "    loss = np.sum(corect_logprobs) / N\n",
    "    return loss\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Higher-level method to do forward_prop in the\n",
    "    whole swarm.\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "    The swarm that will perform the search\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "    The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
    "\n",
    "    return np.array(j)\n",
    "\n",
    "# Initialize swarm\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "# Call instance of PSO\n",
    "dimensions = (4 * 20) + (20 * 3) + 20 + 3\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions,\n",
    "options=options)\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=1000)\n",
    "\n",
    "def predict(X, pos):\n",
    "    \"\"\"\n",
    "    Use the trained weights to perform class predictions.\n",
    "    Inputs\n",
    "    ------\n",
    "    X: numpy.ndarray\n",
    "    Input Iris dataset\n",
    "    pos: numpy.ndarray\n",
    "    Position matrix found by the swarm. Will be rolled\n",
    "    into weights and biases.\n",
    "    \"\"\"\n",
    "    # Neural network architecture\n",
    "    n_inputs = 4\n",
    "    n_hidden = 20\n",
    "    n_classes = 3\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = pos[0:80].reshape((n_inputs,n_hidden))\n",
    "    b1 = pos[80:100].reshape((n_hidden,))\n",
    "    W2 = pos[100:160].reshape((n_hidden,n_classes))\n",
    "    b2 = pos[160:163].reshape((n_classes,))\n",
    "    # Perform forward propagation\n",
    "    \n",
    "    z1 = X.dot(W1) + b1 # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1) # Activation in Layer 1\n",
    "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    logits = z2 # Logits for Layer 2\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred\n",
    "\n",
    "acc=(predict(X, pos) == y).mean()\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
